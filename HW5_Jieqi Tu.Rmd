---
title: "Homework 5"
author: "Jieqi Tu (jt3098)"
date: "11/28/2020"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Question 1

#### (a)
The Bayesian model would be $\bar x|\mu \sim N(\mu, \frac{3^2}{7})$ and here our prior is $\mu \sim Cauchy(5,2)$.
```{r q1 p1}
# Import data
x = c(6.52, 8.32, 0.31, 2.82, 9.96, 0.14, 9.64)
xbar = mean(x)

# Construct Bayesian Model
likelihood.function = function(mu) {
  1/sqrt(2*pi*9/7) * exp(-(xbar - mu)^2/(2*9/7))
}

prior.function = function(mu) {
  1/(pi*2*(1 + ((mu - 5)/2)^2))
}
```

Then we need to find the normalizating constant k. Here we need to perform a variable transformation.
Let $\mu=log(\frac{y}{1-y})$, since $-\infty<\mu<\infty$, we will get $0<y<1$.
The Jacobian matrix would be $(1/(y(1-y)))$.
```{r q1 p2}
# define function for y
y.function = function(y) {
  likelihood.function(log(y/(1-y))) * prior.function(log(y/(1-y))) * (1/(y*(1-y)))
}

# Riemann Sum
int_Riemann = function(f, a, b, n = 100000) {
  h = (b-a)/n
  x = seq(a, b, by = h)
  y = f(x)
  result = h*sum(y[1:n])
  return(result)
}

k = round(1/int_Riemann(y.function, 1e-10, 1-1e-10), 5)
k
```

#### (b)
```{r q1 b}
# Define the function for posterior
posterior.function = function(mu) {
  k*likelihood.function(mu)*prior.function(mu)
}

# Riemann Sum
int_Riemann = function(f, a, b, n = 100000) {
  h = (b-a)/n
  x = seq(a, b, by = h)
  y = f(x)
  result = h*sum(y[1:n])
  return(result)
}

# Trapezoidal Rule
int_trapzoidal = function(f, a, b, n = 100000) {
  h = (b - a)/n
  x = seq(a, b, by = h)
  y = f(x)
  result = h * (y[1] + 2*sum(y[2:n]) + y[n+1]) / 2
  return(result) 
}

# Simpson's Rule
int_Simpson = function(f, a, b, n = 100000) { 
  h = (b - a)/n
  x = seq(a, b, by = h)
  y = f(x)
  if (n == 2) {
    result = (h/3) * (y[1] + 4*y[2] + y[3])
  } else {
    result = (h/3) * (y[1] + sum(2*y[seq(2, n, by = 2)]) + sum(4*y[seq(3, n-1, by = 2)]) + y[n+1])
    }
  return(result)
}

# Calculate the posterior probability that 2 <= mu <= 8
data.frame(Method = c("Riemann", "Trapezoidal", "Simpson's"),
           Result = c(int_Riemann(posterior.function, 2, 8),int_trapzoidal(posterior.function, 2, 8), int_Simpson(posterior.function, 2, 8)))
```

All of these three results are close to 0.99605. However, Trapezoidal method has a little bit higher value of integration than the other two methods.

#### (c)
We still need to perform variable transformation before integration.
Let $\mu = log(\frac{u}{1-u})$. Since $3 \le\mu \le \infty$, we have $\frac{e^3}{1+e^3}<\mu<1$. The Jacobian matrix would be $\frac{1}{u(1-u)}$.
```{r q1 c}
# define the posterior function
posterior.function.u = function(u) {
  k*likelihood.function(log(u/(1-u))) * prior.function(log(u/(1-u))) * (1/(u*(1-u)))
}

# Use Riemann sum method
int_Riemann(posterior.function.u, exp(3)/(1+exp(3)), 1-1e-10)
```

#### (d)
Perform variable transformation: $\mu = 1/u$ and then $0<u<1/3$. The Jacobian matrix is $1/u^2$.
```{r q1 d}
# define the posterior function
posterior.function.u = function(u) {
  k*likelihood.function(1/u) * prior.function(1/u) * (1/u^2)
}

int_Riemann(posterior.function.u, 1e-10, 1/3)
```

From (c) and (d), we know that, both results are very close to 0.99086. However, the transformation in (c) is more close.